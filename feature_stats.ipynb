{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"/Users/danylewin/thingies/university/CS Workshop/Finney/data/PassFInder_Password_Dataset/password_test.csv\",\n",
    "    header=None,\n",
    "    names=[\"text\", \"label\"],\n",
    ")\n",
    "df.sample(20)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def display(data):\n",
    "    # Exclude 'text' and 'label' columns\n",
    "    cols_to_sum = data.columns.difference([\"text\", \"label\"])\n",
    "\n",
    "    # Group by label and sum the rest\n",
    "    result = data.groupby(\"label\")[cols_to_sum].sum()\n",
    "\n",
    "    print(result)"
   ],
   "id": "e580766956f632a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df[\"special\"] = df[\"text\"].str.contains(\"[!@#\\$\\^\\&\\*\\(\\)_\\+\\[\\]'\\\"\\;\\/\\,\\>\\<\\\\\\|\\{\\}\\?\\.]\", regex=True)\n",
    "df[\"special_end\"] = df[\"text\"].str.contains(\"[^a-zA-Z0-9]$\", regex=True)\n",
    "df[\"upper_start\"] = df[\"text\"].str.contains(\"^[A-Z]\", regex=True)\n",
    "df[\"space\"] = df[\"text\"].str.contains(\" \")\n",
    "df.sample(10)\n",
    "# df.groupby(\"label\")[[\"special\", \"special_end\", \"upper_start\", \"space\"]].sum()\n",
    "display(df)"
   ],
   "id": "3b9ef202f0180591",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df[\"all_hexa\"] = df[\"text\"].str.contains(\"^[0-9A-Fa-f]*[A-Fa-f][0-9A-Fa-f]*$\", regex=True)\n",
    "df[\"byte\"] = df[\"text\"].str.contains(r\"\\\\{1,2}\\w{3,4}(?!\\w)\", regex=True)\n",
    "# df[\"new_line\"] = df[\"text\"].str.contains(r\"\\n\",regex=True)\n",
    "display(df)"
   ],
   "id": "6d783946a9a2b85c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df[df.fillna(0).all_hexa > 0]",
   "id": "88f2b846d2f141e1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df[\"path_sub\"] = df[\"text\"].str.contains(r\"(^/\\./)|(^\\./)\", regex=True)\n",
    "df[\"path_relative\"] = df[\"text\"].str.contains(r\"(^/\\.\\./)|(^\\.\\./)\", regex=True)\n",
    "display(df)\n"
   ],
   "id": "92be6feddcaddf1c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df[\"letter_number_symbol\"] = df[\"text\"].str.contains(r\"^[A-Za-z]+[0-9]+\\W?$\", regex=True)\n",
    "df[\"letter_symbol_number\"] = df[\"text\"].str.contains(r\"^[A-Za-z]+\\W?[0-9]+$\", regex=True)\n",
    "display(df)"
   ],
   "id": "190b648a59e8e2b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df[\"year\"] = df[\"text\"].str.contains(r\"\\b(19[0-9]{2}|20[0-9]{2}|2100)\\b\", regex=True)\n",
    "df[\"date\"] = df[\"text\"].str.contains(r\"\\d{4}-\\d{2}-\\d{2}\", regex=True)\n",
    "display(df)"
   ],
   "id": "2824a34138ef7954",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df[\"xml\"] = df[\"text\"].str.contains(r\"<.{1,3}>\", regex=True)\n",
    "df[\"period\"] = df[\"text\"].str.contains(\"\\.\")\n",
    "df[\"double_colon\"] = df[\"text\"].str.contains(\"::\")\n",
    "df[\"question\"] = df[\"text\"].str.contains(\"\\?\")\n",
    "df[\"percent\"] = df[\"text\"].str.contains(\"%\")\n",
    "df[\"arrow\"] = df[\"text\"].str.contains(\"->\")\n",
    "df[\"dunder\"] = df[\"text\"].str.contains(\"__\")\n",
    "df[\"double_equal\"] = df[\"text\"].str.contains(\"==\")\n",
    "df[\"triple_equal\"] = df[\"text\"].str.contains(\"===\")\n",
    "df[\"double_slash\"] = df[\"text\"].str.contains(\"//\")\n",
    "df[\"backslash\"] = df[\"text\"].str.contains(\"\\\\\\\\\")\n",
    "df[\"double_backslash\"] = df[\"text\"].str.contains(\"\\\\\\\\\\\\\\\\\")\n",
    "df[\"newline\"] = df[\"text\"].str.contains(r\"\\\\n\", regex=True)\n",
    "display(df)"
   ],
   "id": "620b433123a46c97",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df[\"balanced_parentheses\"] = (\n",
    "        (df[\"text\"].str.count(r\"\\(\") == df[\"text\"].str.count(r\"\\)\")) &\n",
    "        (df[\"text\"].str.count(r\"\\(\") > 0)\n",
    ")\n",
    "df[\"balanced_parentheses_square\"] = (\n",
    "        (df[\"text\"].str.count(r\"\\[\") == df[\"text\"].str.count(r\"\\]\")) &\n",
    "        (df[\"text\"].str.count(r\"\\[\") > 0)\n",
    ")\n",
    "df[\"balanced_parentheses_curl\"] = (\n",
    "        (df[\"text\"].str.count(r\"\\{\") == df[\"text\"].str.count(r\"\\}\")) &\n",
    "        (df[\"text\"].str.count(r\"\\{\") > 0)\n",
    ")\n",
    "display(df)"
   ],
   "id": "9551ac2e60f0a172",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.sample(10)",
   "id": "b08f0d5bb7af306f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "import re",
   "id": "8a9050bdcab4b418",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df[\"longest_upper\"] = df[\"text\"].apply(\n",
    "    lambda x: max((len(m) for m in re.findall(r\"[A-Z]+\", str(x))), default=0)\n",
    ")\n",
    "display(df)"
   ],
   "id": "1c890ed76125fd22",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df[\"longest_vowels\"] = df[\"text\"].apply(\n",
    "    lambda x: max((len(m) for m in re.findall(r\"[aeiouAEIOU]+\", str(x))), default=0)\n",
    ")\n",
    "df[\"longest_cons\"] = df[\"text\"].apply(\n",
    "    lambda x: max((len(m) for m in re.findall(r\"[bcdfghjklmnpqrstvxzBCDFGHJKLMNPQRSTVXZ]+\", str(x))), default=0)\n",
    ")\n",
    "df[\"longest_hexa\"] = df[\"text\"].apply(\n",
    "    lambda x: max((len(m) for m in re.findall(r\"[0-9A-Fa-f]*[A-Fa-f][0-9A-Fa-f]*\", str(x))), default=0)\n",
    ")\n",
    "display(df)"
   ],
   "id": "def5decb50202c44",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df[\"digit_fraction\"] = df[\"text\"].apply(\n",
    "    lambda x: sum(c.isdigit() for c in str(x)) / len(str(x))\n",
    ")\n",
    "df[\"vowel_fraction\"] = df[\"text\"].apply(\n",
    "    lambda x: sum(c in set(\"aeiouAEIOU\") for c in str(x)) / len(str(x))\n",
    ")\n",
    "df[\"nonword_fraction\"] = df[\"text\"].apply(\n",
    "    lambda x: len(re.findall(r\"\\W\", str(x))) / len(str(x))\n",
    ")\n",
    "display(df)"
   ],
   "id": "41ddae9eeb076ad1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df[\"word_length_mod_4\"] = df[\"text\"].apply(\n",
    "    lambda x: sum(1 for m in re.findall(r\"\\w+\", str(x)) if len(m) % 4 == 0)\n",
    ")\n",
    "display(df)"
   ],
   "id": "4df685c23cbd801f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "p1 = r'^[A-Za-z]+(?:_[A-Za-z_]+)+$'  # snake\n",
    "p2 = r'^[A-Z][a-z]+(?:[A-Z][a-z]+)+$'  # UpperCamel\n",
    "p3 = r'^[a-z]+(?:[A-Z][a-z]+)+$'  # lowerCamel\n",
    "p4 = r'^[A-Za-z]+(?:-[A-Za-z-]+)+$'  # kebab-like (at least one \"-\")\n",
    "p5 = r'^[A-Z]+$'  # ALLCAPS\n",
    "\n",
    "conds = [\n",
    "    df[\"text\"].str.fullmatch(p1, na=False),\n",
    "    df[\"text\"].str.fullmatch(p2, na=False),\n",
    "    df[\"text\"].str.fullmatch(p3, na=False),\n",
    "    df[\"text\"].str.fullmatch(p4, na=False),\n",
    "    df[\"text\"].str.fullmatch(p5, na=False),\n",
    "]\n",
    "\n",
    "df[\"format\"] = np.select(conds, [1, 2, 3, 4, 5], default=0).astype(int)\n",
    "display(df)"
   ],
   "id": "ab775c9006d41415",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# words = pd.read_csv(\"/Users/danylewin/thingies/university/CS Workshop/Finney/data/words.txt\", header=None, names=[\"word\"])\n",
    "# wordset = set(words[\"word\"].astype(str))\n",
    "\n",
    "english_words = set()\n",
    "with open(\"data/words.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        english_words.add(line.strip().casefold())\n",
    "temp = \"|\".join(map(re.escape, english_words))\n",
    "english_pattern = re.compile(rf\"\\b(?:{temp})\\b\")\n",
    "\n",
    "df[\"word\"] = df[\"text\"].astype(str).str.contains(english_pattern, na=False, regex=True)\n",
    "display(df)"
   ],
   "id": "7913d7cc34009f09",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df[\"word_count\"] = df[\"text\"].astype(str).str.findall(english_pattern).str.len()\n",
    "display(df)"
   ],
   "id": "f5f1f33b855bd075",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "keywords = set()\n",
    "with open(\"data/keywords.txt\", \"r\") as f:  # taken from https://github.com/e3b0c442/keywords?tab=readme-ov-file\n",
    "    for line in f.readlines():  # and from https://www.ibm.com/docs/en/i/7.6.0?topic=extensions-standard-c-library-functions-table-by-name\n",
    "        keywords.add(line.strip().casefold())\n",
    "temp = \"|\".join(map(re.escape, keywords))\n",
    "keyword_pattern = re.compile(rf\"\\b(?:{temp})\\b\")\n",
    "\n",
    "df[\"keyword\"] = df[\"text\"].astype(str).str.contains(keyword_pattern, na=False, regex=True)\n",
    "df[\"keyword_count\"] = df[\"text\"].astype(str).str.findall(keyword_pattern).str.len()\n",
    "display(df)"
   ],
   "id": "6c8dfacd6425a83",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "domains = set()  # taken from https://github.com/datasets/top-level-domain-names/blob/main/data/top-level-domain-names.csv?plain=1\n",
    "with open(\"data/domains.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        domains.add(line.strip().casefold())\n",
    "temp = \"|\".join(map(re.escape, domains))\n",
    "url_pattern = re.compile(rf\"(?:{temp})\\b\")\n",
    "\n",
    "df[\"likely_url\"] = df[\"text\"].astype(str).str.contains(url_pattern, na=False)\n",
    "display(df)"
   ],
   "id": "e5d299955cefdef6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "extensions = set()  # taken from https://gist.github.com/securifera/e7eed730cbe1ce43d0c29d7cd2d582f4\n",
    "with open(\"data/extensions.txt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        extensions.add(line.strip().casefold())\n",
    "temp = \"|\".join(map(re.escape, extensions))\n",
    "file_type_pattern = re.compile(rf\"(?:{temp})$\")\n",
    "\n",
    "df[\"file_suffix\"] = df[\"text\"].astype(str).str.contains(url_pattern, na=False)\n",
    "display(df)"
   ],
   "id": "1035844f5a9cdc4f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df[\"string_length\"] = df[\"text\"].astype(str).str.len()",
   "id": "f68e99b1b3f35019",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "key_distances = pd.read_csv(\"/Users/danylewin/thingies/university/CS Workshop/Finney/data/bigrams.csv\",\n",
    "                            index_col=0).to_numpy()\n",
    "key_index = {ch: i for i, ch in enumerate(\"!@#$%^&*()_+1234567890-=qwertyuiop[]{}asdfghjkl;'\\\\:\\\"|~zxcvbnm,./<>?)}\")}\n",
    "\n",
    "character_type_map = defaultdict(int)\n",
    "for c in \"abcdefghijklmnopqrstuvwxyz\":\n",
    "    character_type_map[c] = 1\n",
    "for c in \"0123456789\":\n",
    "    character_type_map[c] = 2\n",
    "\n",
    "\n",
    "def extract_bigrams(word: str) -> list[tuple[str, str]]:\n",
    "    if type(word) != str or len(word) < 2:\n",
    "        return []\n",
    "    word = word.lower().strip()\n",
    "    return list(zip(word, word[1:]))\n",
    "\n",
    "\n",
    "def avg_key_distance(bigrams: list[tuple[str, str]]) -> np.float32:\n",
    "    total_distance = np.float32(0)\n",
    "    if not bigrams:\n",
    "        return total_distance\n",
    "    for bigram in bigrams:\n",
    "        c1, c2 = bigram\n",
    "        if c1 not in key_index or c2 not in key_index:\n",
    "            continue\n",
    "        total_distance += key_distances[key_index[c1]][key_index[c2]]  # type: ignore\n",
    "    return total_distance / len(bigrams)\n",
    "\n",
    "\n",
    "def count_type_switches(bigrams: list[tuple[str, str]]) -> int:\n",
    "    switch_count = 0\n",
    "    for bigram in bigrams:\n",
    "        c1, c2 = bigram\n",
    "        switch_count += character_type_map[c1] != character_type_map[c2]\n",
    "    return switch_count\n",
    "\n",
    "\n",
    "def extract_trigrams(word: str) -> list[tuple[str, str, str]]:\n",
    "    if type(word) != str or len(word) < 3:\n",
    "        return []\n",
    "    word = word.lower().strip()\n",
    "    return list(zip(word, word[1:], word[2:]))\n",
    "\n",
    "\n",
    "def has_consecutive_sequence(trigrams: list[tuple[str, str, str]]) -> bool:\n",
    "    for trigram in trigrams:\n",
    "        c1, c2, c3 = trigram\n",
    "        if abs(ord(c1) - ord(c2)) == 1 and ord(c1) - ord(c2) == ord(c2) - ord(c3):\n",
    "            return True\n",
    "    return False"
   ],
   "id": "3e9bf57d7df72ddd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# split the word into bigrams (e.g. \"bigram\" -> [bi, ig, gr, ra, am])\n",
    "bigrams = df.text.map(lambda word: extract_bigrams(word))\n",
    "df[\"key_distances\"] = list(map(avg_key_distance, bigrams))\n",
    "df[\"type_switches\"] = list(map(count_type_switches, bigrams))\n",
    "\n",
    "# split the word into trigrams (e.g. \"trigram\" -> [tri, rig, igr, gra, ram])\n",
    "trigrams = df.text.map(lambda word: extract_trigrams(word))\n",
    "df[\"consecutive_sequence\"] = list(map(has_consecutive_sequence, trigrams))"
   ],
   "id": "56169ebe6d7f13d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.sample(10)",
   "id": "78c4ab2971b8c43d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "def stats(data):\n",
    "    # Example: identify column types\n",
    "    bool_cols = data.select_dtypes(include=bool).columns\n",
    "    obj_cols = data.select_dtypes(include=object).columns.difference(['label', 'text'])\n",
    "    num_cols = data.select_dtypes(include=[np.number]).columns.difference(['label'])\n",
    "    # (exclude 'label' itself if it's numeric)\n",
    "\n",
    "    # Build aggregation dictionary\n",
    "    agg_dict = {col: 'sum' for col in bool_cols}  # count of True\n",
    "    agg_dict.update({col: 'sum' for col in obj_cols})  # count of True\n",
    "    agg_dict.update({col: 'mean' for col in num_cols})  # average for numeric\n",
    "\n",
    "    # Group by label\n",
    "    results = data.groupby('label').agg(agg_dict).reset_index()\n",
    "    return results\n",
    "\n",
    "\n",
    "print(stats(df))"
   ],
   "id": "6e7c30014ef6843d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df.groupby('label').count()",
   "id": "21cbbb0420a83f14",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def to_csv(data: pd.DataFrame):\n",
    "    data.to_csv(\"feature_stats.csv\", index=False)\n",
    "\n",
    "# to_csv(stats(df))\n",
    "# df.to_csv(\"feature_stats_raw.csv\", index=False)"
   ],
   "id": "5adb5aa3147641b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(df.dtypes)",
   "id": "67175ddc5979607c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "out_path = \"plots\"\n",
    "\n",
    "int_cols = [\n",
    "    {\n",
    "        \"title\": \"Longest uppercase sequence\",\n",
    "        \"x_axis\": \"Sequence length\",\n",
    "        \"column\": \"longest_upper\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Longest vowel sequence\",\n",
    "        \"x_axis\": \"Sequence length\",\n",
    "        \"column\": \"longest_vowels\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Longest consonant sequence\",\n",
    "        \"x_axis\": \"Sequence length\",\n",
    "        \"column\": \"longest_cons\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Longest hexadecimal sequence\",\n",
    "        \"x_axis\": \"Sequence length\",\n",
    "        \"column\": \"longest_hexa\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Number of sequences of length divisible by 4\",\n",
    "        \"x_axis\": \"# of sequences\",\n",
    "        \"column\": \"word_length_mod_4\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"English words\",\n",
    "        \"x_axis\": \"# of contained English words\",\n",
    "        \"column\": \"word_count\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Programming keywords\",\n",
    "        \"x_axis\": \"# of contained programming keywords\",\n",
    "        \"column\": \"keyword_count\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"String length\",\n",
    "        \"x_axis\": \"Length\",\n",
    "        \"column\": \"string_length\"\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Character type switches\",\n",
    "        \"x_axis\": \"# of type switches\",\n",
    "        \"column\": \"type_switches\"\n",
    "    },\n",
    "]\n",
    "\n",
    "labels = {\n",
    "    0: \"Ordinary string\",\n",
    "    1: \"Human password\",\n",
    "    2: \"Computer password\"\n",
    "}\n",
    "\n",
    "for col in int_cols:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for label in [0, 1, 2]:\n",
    "        series = df[df.label == label][col[\"column\"]].dropna().value_counts(sort=False).sort_index()\n",
    "        plt.plot(series.index, series, label=labels[label])\n",
    "        plt.xlabel(col[\"x_axis\"], fontweight=\"bold\")\n",
    "    plt.ylabel(\"Count (log scale)\", fontweight=\"bold\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.title(\n",
    "        col[\"title\"],\n",
    "        fontsize=16,\n",
    "        color=\"brown\",\n",
    "        fontweight=\"bold\",\n",
    "        fontstyle=\"italic\",\n",
    "    )\n",
    "    plt.savefig(f\"plots/{col['column']}.png\")\n",
    "    print(f\"Saved result to {col['column']}\")\n"
   ],
   "id": "bff5d7073a93ea8a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for col in [\"format\"]:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    for label in [0, 1, 2]:\n",
    "        series = df[df.label == label][\"format\"].dropna().value_counts(sort=False).sort_index()\n",
    "        plt.plot([\"snake_case\", \"PascalCase\", \"camelCase\", \"kebab-case\", \"ALLCAPS\"], series[1:], label=labels[label])\n",
    "        plt.xlabel(\"String Format\", fontweight=\"bold\")\n",
    "    plt.ylabel(\"Count\", fontweight=\"bold\")\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.title(\n",
    "        \"Special string formats\",\n",
    "        fontsize=16,\n",
    "        color=\"brown\",\n",
    "        fontweight=\"bold\",\n",
    "        fontstyle=\"italic\",\n",
    "    )\n",
    "    plt.savefig(f\"plots/format.png\")\n",
    "    print(f\"Saved result to format\")\n",
    "    \n",
    "    print(df.groupby([\"label\", \"format\"]).count())\n"
   ],
   "id": "d6c52ad1f16eaed6",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
